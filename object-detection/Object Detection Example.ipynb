{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "273aaf5c-80ea-4d8a-9bbc-721b25afe07e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Object Detection: Moving towards a production pipeline\n",
    "\n",
    "This example illustrates a common Object Detection use case using [Pachyderm](https://www.pachyderm.com/), [Lightning Flash](https://lightning-flash.readthedocs.io/en/latest/), and [Label Studio](https://labelstud.io/). \n",
    "\n",
    "<p align=\"center\">\n",
    "\t<img src='images/diagram.png' width='500' title='Pachyderm'>\n",
    "</p>\n",
    "\n",
    "This demo mimics the object detection [example from Lightning Flash](https://lightning-flash.readthedocs.io/en/stable/reference/object_detection.html#example). We extend the example to predict on new data that can be used to produce predictions for the [Pachyderm Label Studio integration](https://github.com/pachyderm/label-studio) to refine and improve your training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d2fbab-141d-47e9-9eb4-977c7281e022",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1: Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d55c01-6d43-4c13-b038-fdc5c1927496",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/zhiqwang/yolov5-rt-stack/releases/download/v0.3.0/coco128.zip\n",
    "!unzip coco128.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a2588bf-60a1-4862-a8c4-14635d587840",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl create repo coco128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8cebfc-484b-4518-88b1-58a4785f1561",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pachctl put file -r coco128@master:/coco128/ -f coco128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905b7c2-efab-4f76-b576-063f84b7e7e2",
   "metadata": {},
   "source": [
    "## Step 2: Train Model\n",
    "Our model pipeline will train an object detection model on our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae76fe7f-0f98-4bbe-97db-800f927cb0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl create pipeline -f pachyderm/model.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11b8d47-ed24-433a-93ca-155ecf4498b5",
   "metadata": {},
   "source": [
    "Alternatively, you can train your model and track it with [Weights and Biases](https://wandb.ai/site) by configuring a Pachyderm secret and deploying the [model_wandb.json pipeline](pachyderm/model_wandb.json).\n",
    "\n",
    "You can see more about the W&B integration [here](https://github.com/pachyderm/examples/tree/master/weights_and_biases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564fd356-75a8-4ea0-9a8f-86bdb78cb826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wandb secret\n",
    "# !pachctl create secret -f wandb_secret.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a4310-2437-46e1-ae5b-39e1951d170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pachctl update pipeline -f pachyderm/model_wandb.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b328068-24e9-4663-a87b-a1ff9d823694",
   "metadata": {},
   "source": [
    "## Step 3: Predict on Inference Data\n",
    "Our `predictions` pipeline uses combines our `inference_images` data repo with the output of our model pipeline. \n",
    "\n",
    "In this example, we cross these two inputs via the spec: \n",
    "```yaml\n",
    "input:\n",
    "  cross:\n",
    "  - pfs:\n",
    "      repo: inference_images\n",
    "      glob: \"/*\"\n",
    "  - pfs:\n",
    "      repo: model\n",
    "      glob: \"/\"\n",
    "```\n",
    "\n",
    "This means that each time an image is added or changed in `inference_images` it will be processed independently. But whenever our model is retrained, we will reprocess all of our inference_images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb2d1cf6-b314-4ed9-a141-84993f60bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add inference data\n",
    "!pachctl create repo inference_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e48ee0ae-1fbf-4dd7-b7d0-465d73405a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy prediction pipeline\n",
    "!pachctl create pipeline -f pachyderm/predictions.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca0cc552-6405-4b40-93ac-ee1530a9da1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/dog1.jpeg 108.13 KB / 108.13 KB [===========================] 0s 0.00 b/s\n",
      "\u001b[1A\u001b[Jimages/dog1.jpeg 108.13 KB / 108.13 KB [===========================] 0s 0.00 b/s\n",
      "\u001b[1A\u001b[Jimages/dog1.jpeg 108.13 KB / 108.13 KB [===========================] 0s 0.00 b/s\n",
      "\u001b[1A\u001b[Jimages/dog1.jpeg 108.13 KB / 108.13 KB [===========================] 0s 0.00 b/s\n",
      "\u001b[1A\u001b[Jimages/dog1.jpeg 108.13 KB / 108.13 KB [===========================] 0s 0.00 b/s\n"
     ]
    }
   ],
   "source": [
    "# Add data to be predicted on (pipelines run automatically)\n",
    "!pachctl put file -r inference_images@master:/dog1.jpeg -f images/dog1.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f7aab-f263-4ba1-ac28-cb9bf033ebdf",
   "metadata": {},
   "source": [
    "We'll now deploy one more pipeline that will let us visualize the bounding boxes our model predicted. Everything is versioned, so if our model changes, then we'll be able to see the difference in our bounding boxs as our model changes over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77217c65-b891-4aa0-b8c1-7b61d9b9238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl create pipeline -f pachyderm/bboxes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4628434a-9ac0-4f7c-9ddd-24db4a6cef7e",
   "metadata": {},
   "source": [
    "## Step 4: Edit Predictions in Label Studio\n",
    "In order to load the predictions into Label Studio, follow the [Label Studio integration](https://github.com/pachyderm/examples/tree/master/label-studio) to run the server locally using our pre-built Docker container, passing it your Pachyderm config. \n",
    "\n",
    "Once it is running, continue with the steps below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16e25809-f954-46bd-831b-258bc8ddd442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels repo to push our annotations to\n",
    "!pachctl create repo labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7907290f-dbef-40fc-a959-6fd975830c68",
   "metadata": {},
   "source": [
    "1. Create a Project in Label Studio.\n",
    "2. On the create Project screen got to `Labeling Setup` and select a type of Object Detection with Bounding Boxes.\n",
    "2. Paste in the class list from `./classes_raw.txt` into the `Add label names` field.\n",
    "3. Configure Label Studio's Cloud Storage to:\n",
    "**Source Storage**: `inference_images@master`, `predictions@master` (make sure to sync inference_images first so the image files exist for the predictions when they're imported)\n",
    "\n",
    "<p align=\"center\">\n",
    "\t<img src='images/inference_images_config.png' width='600' title='Pachyderm'>\n",
    "</p>\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "\t<img src='images/predictions_config.png' width='600' title='Pachyderm'>\n",
    "</p>\n",
    "\n",
    "Note: We need to tread every object as a source file with `inference_images` but not `predictions`.\n",
    "\n",
    "**Target Storage**: `labels`\n",
    "\n",
    "After configuring and syncing everything, your Cloud Storage settings should look like this: \n",
    "\n",
    "<p align=\"center\">\n",
    "\t<img src='images/ls_cloud_storage_config.png' width='600' title='Pachyderm'>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181331ed-498d-4e75-8ecd-e580cfc10bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the classes available\n",
    "#!cat classes_raw.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a812910e-f282-4baa-a909-49d454aa13b6",
   "metadata": {},
   "source": [
    "Now you can edit the labels for your data, and once you're satisfied with your progress, sync your labels to Pachyderm with the `Sync Storage` option on your `labels` data repository in the Cloud Storage settings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877573a5-c614-4688-b201-5c6f731f7801",
   "metadata": {},
   "source": [
    "# Step 5: Update Training Dataset\n",
    "After we've labeled some images in Label Studio, we would naturally want to incorporate these new examples into our training process. To do this, we will deploy a pipeline to transform our Label Studio annotations into a Coco formatted dataset. \n",
    "\n",
    "Inside this pipeline, after our Coco dataset is created, it get's pushed to our dataset repo, `coco128`. Our model pipeline already knows how to combine these datasets and train our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3953e-6e11-4335-a4ba-9353a491cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl auth get-robot-token ls_to_cococ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac02eb4",
   "metadata": {},
   "source": [
    "Add the token generated above to `./pachyderm_secret.json` as the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c235437-7970-479f-b056-2ba75c0e6f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl create secret -f pachyderm_secret.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed693b2b-aa3a-4c7f-941e-87e4785983b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl create pipeline -f pachyderm/ls_to_coco.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2f11b0-82b3-442d-beec-799163c65cfe",
   "metadata": {},
   "source": [
    "Now, everytime we sync our manual edits from Label Studio, it will automatically update our source dataset and kick off a retraining of our object detection model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99025e62-4524-4813-b709-d78fba20c491",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3731a3-fd86-4624-9cec-564cf2ceec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl delete pipeline bboxes\n",
    "!pachctl delete pipeline predictions\n",
    "!pachctl delete pipeline model\n",
    "!pachctl delete pipeline ls_to_coco\n",
    "!pachctl delete repo labels\n",
    "!pachctl delete repo inference_images\n",
    "!pachctl delete repo coco128"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
